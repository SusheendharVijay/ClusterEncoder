{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "enclosed-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "from collections import OrderedDict\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "together-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self,layers,clusters):\n",
    "        super(GraphEncoder,self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(OrderedDict({\n",
    "            \"lin1\": nn.Linear(layers[0],layers[1]),\n",
    "            \"sig1\": nn.Sigmoid(),\n",
    "            \"lin2\": nn.Linear(layers[1],layers[2]),\n",
    "            \"sig2\": nn.Sigmoid(),\n",
    "            \"lin3\": nn.Linear(layers[2],layers[3]),\n",
    "            \"sig3\": nn.Sigmoid(),\n",
    "            \"lin4\": nn.Linear(layers[3],layers[4]),\n",
    "            \"sig4\": nn.Sigmoid(),\n",
    "        }))\n",
    "        \n",
    "        \n",
    "        self.clusters = clusters\n",
    "        self.outputs = {}\n",
    "        \n",
    "        self.layers[0].register_forward_hook(self.get_activation(\"lin1\"))\n",
    "        self.layers[2].register_forward_hook(self.get_activation(\"lin2\"))\n",
    "        self.layers[4].register_forward_hook(self.get_activation(\"lin3\"))\n",
    "        \n",
    "    def get_activation(self,name):\n",
    "        def hook(module,input,output):\n",
    "            self.outputs[name] = output\n",
    "        return hook\n",
    "    \n",
    "    def forward(self,X):\n",
    "        output = self.layers(X)\n",
    "        return output\n",
    "    \n",
    "    def layer_activations(self,layername):\n",
    "        return torch.mean(torch.sigmoid(self.outputs[layername]),dim=0)\n",
    "    \n",
    "    def sparse_result(self,rho,layername):\n",
    "        rho_hat = self.layer_activations(layername)\n",
    "        return rho * np.log(rho) - rho * torch.log(rho_hat) + (1 - rho) * np.log(1 - rho) \\\n",
    "                - (1 - rho) * torch.log(1 - rho_hat)\n",
    "    \n",
    "    def kl_div(self,rho):\n",
    "        first = torch.mean(self.sparse_result(rho,\"lin1\"))\n",
    "        second = torch.mean(self.sparse_result(rho,\"lin2\"))\n",
    "        return first + second\n",
    "    \n",
    "    def get_index_by_name(self,name):\n",
    "        return list(dict(self.layers.named_children()).keys()).index(name)\n",
    "    \n",
    "    def loss(self,x_hat,x,beta,rho):\n",
    "        loss = F.mse_loss(x_hat,x) + beta*self.kl_div(rho)\n",
    "        return loss \n",
    "    \n",
    "    def get_cluster(self):\n",
    "        kmeans = KMeans(n_clusters = self.clusters).fit(self.outputs[\"lin2\"].detach().cpu().numpy())\n",
    "        self.centroids = kmeans.cluster_centers_\n",
    "        return kmeans.labels_\n",
    "    \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aquatic-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from torch import nn,optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "raising-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"wine\",\n",
    "    \"layers\":[128,64,128],\n",
    "    \"beta\": 0.01,\n",
    "    \"rho\":0.5,\n",
    "    \"lr\": 0.01,\n",
    "    \"epoch\": 200,\n",
    "    \"device\":\"gpu\"\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if args[\"device\"] == \"gpu\" else \"cpu\")\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "renewable-bicycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 32.03it/s, loss=tensor(3.1615e-05, device='cuda:0', grad_fn=<AddBackward0>), nmi=0.468]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 1 2 0 1 2 0 2 1 0 1 2 2 2\n",
      " 0 2 2 2 0 2 0 2 2 1 2 2 2 2 2 2 2 2 1 2 0 0 0 2 2 2 2 2 2 2 2 1 2 2 2 2 0\n",
      " 2 1 2 2 0 2 2 1 2 2 2 2 0 0 2 2 1 2 2 1 1 1 1 1 1 0 1 1 2 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if args[\"dataset\"].lower() == \"wine\":\n",
    "        data = load_wine()\n",
    "    else:\n",
    "        raise Exception(\"Invalid Dataset\")\n",
    "    \n",
    "    X  = data.data\n",
    "    y = data.target\n",
    "    k = len(np.unique(y))\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    \n",
    "    S = cosine_similarity(X,X)\n",
    "    \n",
    "    D  = np.diag(1.0/np.sqrt(S.sum(axis=1)))\n",
    "    \n",
    "    X_train = torch.tensor(D.dot(S).dot(D)).float().to(device)\n",
    "    \n",
    "    layers = [len(X_train)] + args[\"layers\"] + [len(X_train)]\n",
    "    \n",
    "    model = GraphEncoder(layers,k).to(device)\n",
    "    optimizer  = optim.Adam(model.parameters(),lr=args[\"lr\"])\n",
    "    \n",
    "    with tqdm(total= args[\"epoch\"]) as tq:\n",
    "        for epoch in range(1,args[\"epoch\"] +1):\n",
    "            optimizer.zero_grad()\n",
    "            X_hat = model(X_train)\n",
    "            loss = model.loss(X_hat,X_train, args[\"beta\"],args[\"rho\"])\n",
    "            nmi = normalized_mutual_info_score(model.get_cluster(),y,average_method=\"arithmetic\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tq.set_postfix(loss=loss,nmi =\"{:.3f}\".format(nmi))\n",
    "            tq.update()\n",
    "        print(model.get_cluster())\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "pretty-solomon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65413719, 0.20846844, 0.80323383, 0.39419593, 0.36052379,\n",
       "       0.99413257, 0.85464362, 0.7769152 , 0.36352331, 0.08104066,\n",
       "       0.29443078, 0.29881754, 0.14381877, 0.07143409, 0.16923219,\n",
       "       0.47633488, 0.37603774, 0.08699661, 0.66034288, 0.4255103 ])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = model.get_cluster()\n",
    "Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "comparative-muscle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 13),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape,data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "current-howard",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad argument type for built-in operation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0db52ddae836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad argument type for built-in operation"
     ]
    }
   ],
   "source": [
    "S = cosine_similarity(data.data,data.data)\n",
    "img = cv2.imshow(S*255.0,cv2.IMREAD_GRAYSCALE)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mineral-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_wine()\n",
    "data.data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "excess-location",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/highgui/src/window.cpp:632: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-83116bc417d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfloat_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_img\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"simi\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/highgui/src/window.cpp:632: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "float_img = np.random.random((4,4))\n",
    "im = np.array(float_img * 255, dtype = np.uint8)\n",
    "cv2.imshow(\"simi\",im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-circus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-northeast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
