{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "interested-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "from collections import OrderedDict\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "oriented-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from torch import nn,optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "small-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self,layers,clusters):\n",
    "        super(GraphEncoder,self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(OrderedDict({\n",
    "            \"lin1\": nn.Linear(layers[0],layers[1]),\n",
    "            \"sig1\": nn.Sigmoid(),\n",
    "            \"lin2\": nn.Linear(layers[1],layers[2]),\n",
    "            \"sig2\": nn.Sigmoid(),\n",
    "            \"lin3\": nn.Linear(layers[2],layers[3]),\n",
    "            \"sig3\": nn.Sigmoid(),\n",
    "            \"lin4\": nn.Linear(layers[3],layers[4]),\n",
    "            \"sig4\": nn.Sigmoid(),\n",
    "        }))\n",
    "        \n",
    "        \n",
    "        self.clusters = clusters\n",
    "        self.outputs = {}\n",
    "        \n",
    "        self.layers[0].register_forward_hook(self.get_activation(\"lin1\"))\n",
    "        self.layers[2].register_forward_hook(self.get_activation(\"lin2\"))\n",
    "        self.layers[4].register_forward_hook(self.get_activation(\"lin3\"))\n",
    "        \n",
    "    def get_activation(self,name):\n",
    "        def hook(module,input,output):\n",
    "            self.outputs[name] = output\n",
    "        return hook\n",
    "    \n",
    "    def forward(self,X):\n",
    "        output = self.layers(X)\n",
    "        return output\n",
    "    \n",
    "    def layer_activations(self,layername):\n",
    "       # print(torch.sigmoid(self.outputs[layername]).shape)\n",
    "        return torch.mean(torch.sigmoid(self.outputs[layername]),dim=0)\n",
    "    \n",
    "    def sparse_result(self,rho,layername):\n",
    "        rho_hat = self.layer_activations(layername)\n",
    "        return rho * np.log(rho) - rho * torch.log(rho_hat) + (1 - rho) * np.log(1 - rho) \\\n",
    "                - (1 - rho) * torch.log(1 - rho_hat)\n",
    "    \n",
    "    def kl_div(self,rho):\n",
    "        first = torch.mean(self.sparse_result(rho,\"lin1\"))\n",
    "        second = torch.mean(self.sparse_result(rho,\"lin2\"))\n",
    "        return first + second\n",
    "    \n",
    "    def get_index_by_name(self,name):\n",
    "        return list(dict(self.layers.named_children()).keys()).index(name)\n",
    "    \n",
    "    def loss(self,x_hat,x,beta,rho):\n",
    "        loss = F.mse_loss(x_hat,x) + beta*self.kl_div(rho)\n",
    "        return loss \n",
    "    \n",
    "    def get_cluster(self):\n",
    "        kmeans = KMeans(n_clusters = self.clusters).fit(self.outputs[\"lin2\"].detach().cpu().numpy())\n",
    "        self.centroids = kmeans.cluster_centers_\n",
    "        return kmeans.labels_\n",
    "    \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "moved-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self,layers):\n",
    "        super(SAE,self).__init__()\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.net = nn.Sequential(OrderedDict({\n",
    "            \"lin1\": nn.Linear(layers[0],layers[1]),\n",
    "            \"sig1\":nn.Sigmoid(),\n",
    "            \"lin2\": nn.Linear(layers[1],layers[2]),\n",
    "            \"sig2\":nn.Sigmoid()\n",
    "        }))\n",
    "        \n",
    "        self.outputs = {}\n",
    "        \n",
    "        self.net[0].register_forward_hook(self.get_activation(\"lin1\"))\n",
    "        \n",
    "        \n",
    "    def get_activation(self,name):\n",
    "        def hook(module,input,output):\n",
    "            self.outputs[name] = output\n",
    "        return hook\n",
    "\n",
    "    def forward(self,X):\n",
    "        output = self.net(X)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def layer_activations(self,layername):\n",
    "        return torch.mean(torch.sigmoid(self.outputs[layername]),dim=0)\n",
    "\n",
    "    def sparse_result(self,rho,layername):\n",
    "        rho_hat = self.layer_activations(layername)\n",
    "        return rho * np.log(rho) - rho * torch.log(rho_hat) + (1 - rho) * np.log(1 - rho) \\\n",
    "            - (1 - rho) * torch.log(1 - rho_hat)\n",
    "\n",
    "    def kl_div(self,rho):\n",
    "        return torch.mean(self.sparse_result(rho,\"lin1\"))\n",
    "\n",
    "    def loss(self,x_hat,x,rho,beta):\n",
    "        loss = F.mse_loss(x_hat,x) + beta*self.kl_div(rho)\n",
    "        return loss\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "secondary-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"wine\",\n",
    "    \"layers\":[128,64,128],\n",
    "    \"beta\": 0.01,\n",
    "    \"rho\":0.5,\n",
    "    \"lr\": 0.01,\n",
    "    \"epoch\": 200,\n",
    "    \"device\":\"gpu\"\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if args[\"device\"] == \"gpu\" else \"cpu\")\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "transsexual-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 30.69it/s, loss=tensor(3.1616e-05, device='cuda:0', grad_fn=<AddBackward0>), nmi=0.491]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 1 0 2 0 0 2 0 1 2 0 0 0 0\n",
      " 2 0 0 0 2 0 2 0 0 1 2 0 0 0 0 0 0 0 1 0 2 2 2 0 2 0 0 0 0 0 0 1 0 0 0 0 2\n",
      " 0 0 0 0 2 0 0 1 0 0 0 0 2 2 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if args[\"dataset\"].lower() == \"wine\":\n",
    "        data = load_wine()\n",
    "    else:\n",
    "        raise Exception(\"Invalid Dataset\")\n",
    "    \n",
    "    X  = data.data\n",
    "    y = data.target\n",
    "    k = len(np.unique(y))\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    \n",
    "    S = cosine_similarity(X,X)\n",
    "    \n",
    "    D  = np.diag(1.0/np.sqrt(S.sum(axis=1)))\n",
    "    \n",
    "    X_train = torch.tensor(D.dot(S).dot(D)).float().to(device)\n",
    "    \n",
    "    layers = [len(X_train)] + args[\"layers\"] + [len(X_train)]\n",
    "    \n",
    "    model = GraphEncoder(layers,k).to(device)\n",
    "    optimizer  = optim.Adam(model.parameters(),lr=args[\"lr\"])\n",
    "    \n",
    "    with tqdm(total= args[\"epoch\"]) as tq:\n",
    "        for epoch in range(1,args[\"epoch\"] +1):\n",
    "            optimizer.zero_grad()\n",
    "            X_hat = model(X_train)\n",
    "            loss = model.loss(X_hat,X_train, args[\"beta\"],args[\"rho\"])\n",
    "            nmi = normalized_mutual_info_score(model.get_cluster(),y,average_method=\"arithmetic\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tq.set_postfix(loss=loss,nmi =\"{:.3f}\".format(nmi))\n",
    "            tq.update()\n",
    "        print(model.get_cluster())\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "antique-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "k = len(np.unique(y))\n",
    "model = GraphEncoder([178,128,64,128,178],k).to(device)\n",
    "sae  = SAE([178,128,178]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "alpha-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cosine_similarity(X,X)\n",
    "X_train = torch.Tensor(X_train).to(device)\n",
    "output = model(X_train)\n",
    "out = sae(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "approximate-chamber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 128])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "satisfied-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer_activations(\"lin1\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cordless-watson",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-c0dda8790928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-d26841c3206e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "hyper = {\n",
    "    \"beta\": 0.01,\n",
    "    \"rho\":0.5,\n",
    "    \"lr\": 0.01,\n",
    "    \"epoch\": 200,\n",
    "\n",
    "}\n",
    "\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "k = len(np.unique(y))\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "S = cosine_similarity(X,X)\n",
    "D  = np.diag(1.0/np.sqrt(S.sum(axis=1)))\n",
    "X_train = torch.tensor(D.dot(S).dot(D)).float().to(device)\n",
    "\n",
    "layers = [128,64,32]\n",
    "for layer in layers:\n",
    "    model = sae(layer)\n",
    "    with tqdm(total=hyper[\"epoch\"]) as tq:\n",
    "        for epoch in range(1,range(hyper[\"epoch\"]+1)):\n",
    "            x_hat = model(X_train)\n",
    "            loss = model.loss()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "rough-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 307.04it/s, loss=tensor(2.4287e-05, device='cuda:0', grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "hyper = {\n",
    "    \"beta\": 0.01,\n",
    "    \"rho\":0.5,\n",
    "    \"lr\": 0.01,\n",
    "    \"epoch\": 200,\n",
    "\n",
    "}\n",
    "\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "k = len(np.unique(y))\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "S = cosine_similarity(X,X)\n",
    "D  = np.diag(1.0/np.sqrt(S.sum(axis=1)))\n",
    "X_train = torch.tensor(D.dot(S).dot(D)).float().to(device)\n",
    "\n",
    "\n",
    "\n",
    "saet = SAE([178,128,178]).to(device)\n",
    "optimizer = optim.Adam(saet.parameters(),lr=hyper[\"lr\"])\n",
    "with tqdm(total=hyper[\"epoch\"]) as tq:\n",
    "        for epoch in range(1,hyper[\"epoch\"]+1):\n",
    "            optimizer.zero_grad()\n",
    "            x_hat = saet(X_train)\n",
    "            loss = saet.loss(x_hat,X_train,hyper[\"rho\"],hyper[\"beta\"])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tq.set_postfix(loss=loss)\n",
    "            tq.update()\n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "pleasant-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = saet(X_train)\n",
    "\n",
    "\n",
    "loss = saet.loss(output,X_train,hyper[\"rho\"],hyper[\"beta\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "about-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-bumper",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
