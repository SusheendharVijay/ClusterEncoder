{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "neither-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "from collections import OrderedDict\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "public-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity,rbf_kernel\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from torch import nn,optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "peaceful-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "written-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self,layers,clusters):\n",
    "        super(GraphEncoder,self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(OrderedDict({\n",
    "            \"lin1\": nn.Linear(layers[0],layers[1]),\n",
    "            \"sig1\": nn.Sigmoid(),\n",
    "            \"lin2\": nn.Linear(layers[1],layers[2]),\n",
    "            \"sig2\": nn.Sigmoid(),\n",
    "            \"lin3\": nn.Linear(layers[2],layers[3]),\n",
    "            \"sig3\": nn.Sigmoid(),\n",
    "            \"lin4\": nn.Linear(layers[3],layers[4]),\n",
    "            \"sig4\": nn.Sigmoid(),\n",
    "        }))\n",
    "        \n",
    "        \n",
    "        self.clusters = clusters\n",
    "        self.outputs = {}\n",
    "        \n",
    "        self.layers[0].register_forward_hook(self.get_activation(\"lin1\"))\n",
    "        self.layers[2].register_forward_hook(self.get_activation(\"lin2\"))\n",
    "        self.layers[4].register_forward_hook(self.get_activation(\"lin3\"))\n",
    "        \n",
    "    def get_activation(self,name):\n",
    "        def hook(module,input,output):\n",
    "            self.outputs[name] = output\n",
    "        return hook\n",
    "    \n",
    "    def forward(self,X):\n",
    "        output = self.layers(X)\n",
    "        return output\n",
    "    \n",
    "    def layer_activations(self,layername):\n",
    "       # print(torch.sigmoid(self.outputs[layername]).shape)\n",
    "        return torch.mean(torch.sigmoid(self.outputs[layername]),dim=0)\n",
    "    \n",
    "    def sparse_result(self,rho,layername):\n",
    "        rho_hat = self.layer_activations(layername)\n",
    "        return rho * np.log(rho) - rho * torch.log(rho_hat) + (1 - rho) * np.log(1 - rho) \\\n",
    "                - (1 - rho) * torch.log(1 - rho_hat)\n",
    "    \n",
    "    def kl_div(self,rho):\n",
    "        first = torch.mean(self.sparse_result(rho,\"lin1\"))\n",
    "        second = torch.mean(self.sparse_result(rho,\"lin2\"))\n",
    "        return first + second\n",
    "    \n",
    "    def get_index_by_name(self,name):\n",
    "        return list(dict(self.layers.named_children()).keys()).index(name)\n",
    "    \n",
    "    def loss(self,x_hat,x,beta,rho):\n",
    "        loss = F.mse_loss(x_hat,x) + beta*self.kl_div(rho)\n",
    "        return loss \n",
    "    \n",
    "    def get_cluster(self):\n",
    "        kmeans = KMeans(n_clusters = self.clusters).fit(self.outputs[\"lin2\"].detach().cpu().numpy())\n",
    "        self.centroids = kmeans.cluster_centers_\n",
    "        return kmeans.labels_\n",
    "    \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "offensive-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self,input_layer,hidden_layer):\n",
    "        super(SAE,self).__init__()\n",
    "        self.layers = [input_layer] + [hidden_layer] + [input_layer]\n",
    "#         print(self.layers)\n",
    "        self.net = nn.Sequential(OrderedDict({\n",
    "            \"lin1\": nn.Linear(self.layers[0],self.layers[1]),\n",
    "            \"sig1\":nn.Sigmoid(),\n",
    "            \"lin2\": nn.Linear(self.layers[1],self.layers[2]),\n",
    "            \"sig2\":nn.Sigmoid()\n",
    "        }))\n",
    "        \n",
    "        self.outputs = {}\n",
    "        \n",
    "        self.net[0].register_forward_hook(self.get_activation(\"lin1\"))\n",
    "        \n",
    "        \n",
    "    def get_activation(self,name):\n",
    "        def hook(module,input,output):\n",
    "            self.outputs[name] = output\n",
    "        return hook\n",
    "\n",
    "    def forward(self,X):\n",
    "        output = self.net(X)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def layer_activations(self,layername):\n",
    "        return torch.mean(torch.sigmoid(self.outputs[layername]),dim=0)\n",
    "\n",
    "    def sparse_result(self,rho,layername):\n",
    "        rho_hat = self.layer_activations(layername)\n",
    "        return rho * np.log(rho) - rho * torch.log(rho_hat) + (1 - rho) * np.log(1 - rho) \\\n",
    "            - (1 - rho) * torch.log(1 - rho_hat)\n",
    "\n",
    "    def kl_div(self,rho):\n",
    "        return torch.mean(self.sparse_result(rho,\"lin1\"))\n",
    "\n",
    "    def loss(self,x_hat,x,rho,beta):\n",
    "        loss = F.mse_loss(x_hat,x) + beta*self.kl_div(rho)\n",
    "        return loss\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "egyptian-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"wine\",\n",
    "    \"layers\":[128,64,128],\n",
    "    \"beta\": 0.01,\n",
    "    \"rho\":0.5,\n",
    "    \"lr\": 0.01,\n",
    "    \"epoch\": 200,\n",
    "    \"device\":\"gpu\"\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if args[\"device\"] == \"gpu\" else \"cpu\")\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-algeria",
   "metadata": {},
   "source": [
    "## Stacked Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "isolated-transport",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 38.12it/s, loss=tensor(6.2077e-05, device='cuda:0', grad_fn=<AddBackward0>), nmi=0.858]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 2 0 0 0 0 0 0 2 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if args[\"dataset\"].lower() == \"wine\":\n",
    "        data = load_wine()\n",
    "    else:\n",
    "        raise Exception(\"Invalid Dataset\")\n",
    "    \n",
    "    X  = data.data\n",
    "    y = data.target\n",
    "    k = len(np.unique(y))\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    \n",
    "    S = rbf_kernel(X,X,gamma=2)\n",
    "    \n",
    "    D  = np.diag(1.0/S.sum(axis=1))\n",
    "    \n",
    "    X_train = torch.tensor(D.dot(S)).float().to(device)\n",
    "    \n",
    "    layers = [len(X_train)] + args[\"layers\"] + [len(X_train)]\n",
    "    \n",
    "    model = GraphEncoder(layers,k).to(device)\n",
    "    optimizer  = optim.Adam(model.parameters(),lr=args[\"lr\"])\n",
    "    \n",
    "    with tqdm(total= args[\"epoch\"]) as tq:\n",
    "        for epoch in range(1,args[\"epoch\"] +1):\n",
    "            optimizer.zero_grad()\n",
    "            X_hat = model(X_train)\n",
    "            loss = model.loss(X_hat,X_train, args[\"beta\"],args[\"rho\"])\n",
    "            nmi = normalized_mutual_info_score(model.get_cluster(),y,average_method=\"arithmetic\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tq.set_postfix(loss=loss,nmi =\"{:.3f}\".format(nmi))\n",
    "            tq.update()\n",
    "        print(model.get_cluster())\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "clinical-destination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 290.04it/s, loss=tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)]\n",
      " 28%|██▊       | 56/200 [00:00<00:00, 290.95it/s, loss=tensor(1.3317, device='cuda:0', grad_fn=<AddBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 304.15it/s, loss=tensor(1.3217, device='cuda:0', grad_fn=<AddBackward0>)]\n",
      " 28%|██▊       | 56/200 [00:00<00:00, 286.05it/s, loss=tensor(0.1342, device='cuda:0', grad_fn=<AddBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 291.69it/s, loss=tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)]\n",
      " 28%|██▊       | 56/200 [00:00<00:00, 285.08it/s, loss=tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 295.48it/s, loss=tensor(0.1397, device='cuda:0', grad_fn=<AddBackward0>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([178, 16])\n",
      "0.8130458076130239\n"
     ]
    }
   ],
   "source": [
    "hyper = {\n",
    "    \"beta\": 0.05,\n",
    "    \"rho\":0.2,\n",
    "    \"lr\": 0.01,\n",
    "    \"epoch\": 200,\n",
    "    \"gamma\":2\n",
    "\n",
    "}\n",
    "\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "k = len(np.unique(y))\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "S = rbf_kernel(X,X,hyper[\"gamma\"])\n",
    "D  = np.diag(1.0/S.sum(axis=1))\n",
    "X_train = torch.tensor(D.dot(S)).float().to(device)\n",
    "\n",
    "layers = [128,64,32,16]\n",
    "inp_layers = [178,128,64,32]\n",
    "\n",
    "\n",
    "for inp_layer,hidden_layer in zip(inp_layers,layers):\n",
    "    model = SAE(inp_layer,hidden_layer).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=hyper[\"lr\"])\n",
    "    with tqdm(total=hyper[\"epoch\"]) as tq:\n",
    "        for epoch in range(1,hyper[\"epoch\"]+1):\n",
    "            optimizer.zero_grad()\n",
    "            x_hat = model(X_train)\n",
    "            loss = model.loss(x_hat,X_train,hyper[\"rho\"],hyper[\"beta\"])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tq.set_postfix(loss=loss)\n",
    "            tq.update()\n",
    "    print(model.outputs[\"lin1\"].shape)\n",
    "    X_train = model.outputs[\"lin1\"].detach()\n",
    "\n",
    "    \n",
    "    \n",
    "           \n",
    "kmeans = KMeans(n_clusters=k).fit(X_train.detach().cpu().numpy())\n",
    "labels = kmeans.labels_\n",
    "nmi = normalized_mutual_info_score(labels,y,average_method=\"arithmetic\")\n",
    "print(nmi)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "israeli-catalog",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3268, -0.3927, -0.3628,  ..., -0.3250, -0.3502, -0.4169],\n",
       "        [-0.3269, -0.3927, -0.3629,  ..., -0.3257, -0.3507, -0.4174],\n",
       "        [-0.3262, -0.3930, -0.3618,  ..., -0.3246, -0.3498, -0.4173],\n",
       "        ...,\n",
       "        [-0.3215, -0.3909, -0.3597,  ..., -0.3208, -0.3504, -0.4181],\n",
       "        [-0.3221, -0.3907, -0.3595,  ..., -0.3206, -0.3511, -0.4178],\n",
       "        [-0.3207, -0.3911, -0.3594,  ..., -0.3212, -0.3503, -0.4180]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "preliminary-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = X_train.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "wrapped-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim =np.dot(D,S)\n",
    "ev =np.dot(sim,gap)\n",
    "evalue = np.divide(ev,gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "advanced-ethernet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f24f9a66990>]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigen_values =sorted(evalue.mean(axis=0))\n",
    "plt.plot(eigen_values,marker=\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "searching-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "k = len(np.unique(y))\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "S = cosine_similarity(X,X)\n",
    "D  = np.diag(1.0/S.sum(axis=1))\n",
    "X_train = torch.tensor(D.dot(S)).float().numpy()\n",
    "kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "better-exhibit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6351524906645798\n"
     ]
    }
   ],
   "source": [
    "nmi = normalized_mutual_info_score(kmeans.labels_,y,average_method=\"arithmetic\")\n",
    "print(nmi)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceramic-guyana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-redhead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-disaster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
